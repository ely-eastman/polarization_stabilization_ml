{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify GPU and import libraries\n",
        "import os\n",
        "import scipy.io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import GradScaler, autocast\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Tuple\n",
        "\n",
        "# Verify GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA version:\", torch.version.cuda)\n",
        "    print(\"GPU count:\", torch.cuda.device_count())\n",
        "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
        "    print(\"Current device:\", device)\n",
        "else:\n",
        "    print(\"No GPU detected, using CPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and examine the S-parameter data\n",
        "data_path = \"../Data/basic_datasets/data_4.mat\"\n",
        "print(\"Loading S-parameter data from:\", data_path)\n",
        "\n",
        "# Load the .mat file\n",
        "mat_data = scipy.io.loadmat(data_path)\n",
        "\n",
        "# Extract S-parameter data\n",
        "s1_pax = mat_data['s1_pax'].flatten()  # Reference S-parameters\n",
        "s2_pax = mat_data['s2_pax'].flatten()\n",
        "s3_pax = mat_data['s3_pax'].flatten()\n",
        "\n",
        "s1_txp = mat_data['s1_txp'].flatten()  # Input S-parameters\n",
        "s2_txp = mat_data['s2_txp'].flatten()\n",
        "s3_txp = mat_data['s3_txp'].flatten()\n",
        "\n",
        "print(f\"Data shapes:\")\n",
        "print(f\"s1_pax: {s1_pax.shape}, s2_pax: {s2_pax.shape}, s3_pax: {s3_pax.shape}\")\n",
        "print(f\"s1_txp: {s1_txp.shape}, s2_txp: {s2_txp.shape}, s3_txp: {s3_txp.shape}\")\n",
        "\n",
        "# Stack features (inputs) and targets (references)\n",
        "features = np.column_stack([s1_txp, s2_txp, s3_txp])  # 3 input S-parameters\n",
        "targets = np.column_stack([s1_pax, s2_pax, s3_pax])   # 3 reference S-parameters\n",
        "\n",
        "print(f\"\\nCombined data shapes:\")\n",
        "print(f\"Features (inputs): {features.shape}\")\n",
        "print(f\"Targets (references): {targets.shape}\")\n",
        "\n",
        "# Display some statistics\n",
        "print(f\"\\nS-parameter ranges:\")\n",
        "print(f\"Input S-parameters - min: {features.min():.6f}, max: {features.max():.6f}\")\n",
        "print(f\"Reference S-parameters - min: {targets.min():.6f}, max: {targets.max():.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset class - modified from original to handle 3 S-parameters instead of 2 angles\n",
        "class SParameterDataset(Dataset):\n",
        "    def __init__(self, features: np.ndarray, targets: np.ndarray, window_size: int, indices: np.ndarray = None):\n",
        "        \"\"\"\n",
        "        Dataset for S-parameter prediction\n",
        "        \n",
        "        Args:\n",
        "            features: Input S-parameters (N, 3)\n",
        "            targets: Target S-parameters (N, 3) \n",
        "            window_size: Size of the sliding window\n",
        "            indices: Optional indices for train/test split\n",
        "        \"\"\"\n",
        "        # Check for NaN or infinite values\n",
        "        if np.isnan(features).any() or np.isnan(targets).any():\n",
        "            print(\"Warning: NaN values found in data!\")\n",
        "            valid_mask = ~(np.isnan(features).any(axis=1) | np.isnan(targets).any(axis=1))\n",
        "            features = features[valid_mask]\n",
        "            targets = targets[valid_mask]\n",
        "            \n",
        "        if np.isinf(features).any() or np.isinf(targets).any():\n",
        "            print(\"Warning: Infinite values found in data!\")\n",
        "            valid_mask = ~(np.isinf(features).any(axis=1) | np.isinf(targets).any(axis=1))\n",
        "            features = features[valid_mask]\n",
        "            targets = targets[valid_mask]\n",
        "        \n",
        "        # Normalize the data\n",
        "        self.features_mean = np.mean(features, axis=0)\n",
        "        self.features_std = np.std(features, axis=0) + 1e-8\n",
        "        self.targets_mean = np.mean(targets, axis=0)\n",
        "        self.targets_std = np.std(targets, axis=0) + 1e-8\n",
        "        \n",
        "        self.features = (features - self.features_mean) / self.features_std\n",
        "        self.targets = (targets - self.targets_mean) / self.targets_std\n",
        "        \n",
        "        print(f\"Normalized features range: {self.features.min():.3f} to {self.features.max():.3f}\")\n",
        "        print(f\"Normalized targets range: {self.targets.min():.3f} to {self.targets.max():.3f}\")\n",
        "        \n",
        "        self.window_size = window_size\n",
        "        self.indices = indices if indices is not None else np.arange(len(self.features) - window_size + 1)\n",
        "        self.length = len(self.indices)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
        "        data_idx = self.indices[idx]\n",
        "        window = self.features[data_idx:data_idx + self.window_size]\n",
        "        target = self.targets[data_idx + self.window_size - 1]\n",
        "        time_index = data_idx + self.window_size - 1\n",
        "        return torch.FloatTensor(window), torch.FloatTensor(target), time_index\n",
        "    \n",
        "    def denormalize_predictions(self, predictions):\n",
        "        \"\"\"Convert normalized predictions back to original scale\"\"\"\n",
        "        if isinstance(predictions, torch.Tensor):\n",
        "            predictions = predictions.cpu().numpy()\n",
        "        return predictions * self.targets_std + self.targets_mean\n",
        "    \n",
        "    def denormalize_targets(self, targets):\n",
        "        \"\"\"Convert normalized targets back to original scale\"\"\"\n",
        "        if isinstance(targets, torch.Tensor):\n",
        "            targets = targets.cpu().numpy()\n",
        "        return targets * self.targets_std + self.targets_mean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model definition - modified from original to handle 3 inputs/outputs instead of 2\n",
        "class FlashAttention(nn.Module):\n",
        "    def __init__(self, d_model: int, n_heads: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_k = d_model // n_heads\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.qkv = nn.Linear(d_model, 3 * d_model)\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "        \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        B, T, C = x.shape\n",
        "        qkv = self.qkv(x).reshape(B, T, 3, self.n_heads, self.d_k).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        \n",
        "        scale = 1.0 / torch.sqrt(torch.tensor(self.d_k, dtype=torch.float32))\n",
        "        attn = torch.matmul(q, k.transpose(-2, -1)) * scale\n",
        "        attn = F.softmax(attn, dim=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        \n",
        "        out = torch.matmul(attn, v)\n",
        "        out = out.transpose(1, 2).reshape(B, T, C)\n",
        "        out = self.out(out)\n",
        "        return out\n",
        "\n",
        "class SParameterPredictionModel(nn.Module):\n",
        "    def __init__(self, input_dim: int, d_model: int, n_heads: int, n_layers: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.d_model = d_model\n",
        "        \n",
        "        self.input_proj = nn.Linear(input_dim, d_model)\n",
        "        self.pos_encoding = nn.Parameter(torch.randn(1, 128, d_model) * 0.1)\n",
        "        self.attn_layers = nn.ModuleList([\n",
        "            FlashAttention(d_model, n_heads, dropout) for _ in range(n_layers)\n",
        "        ])\n",
        "        self.norm_layers = nn.ModuleList([\n",
        "            nn.LayerNorm(d_model) for _ in range(n_layers)\n",
        "        ])\n",
        "        self.output = nn.Linear(d_model, 3)  # Output 3 S-parameters instead of 2\n",
        "        \n",
        "        self.apply(self._init_weights)\n",
        "    \n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.input_proj(x)\n",
        "        x = x + self.pos_encoding[:, :x.size(1), :]\n",
        "        \n",
        "        for attn, norm in zip(self.attn_layers, self.norm_layers):\n",
        "            residual = x\n",
        "            x = attn(x)\n",
        "            x = norm(x + residual)\n",
        "        \n",
        "        x = x[:, -1, :]\n",
        "        return self.output(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataset and data loaders\n",
        "window_size = 64\n",
        "batch_size = 64\n",
        "\n",
        "dataset_full = SParameterDataset(features, targets, window_size)\n",
        "total_length = len(dataset_full)\n",
        "train_length = int(0.8 * total_length)\n",
        "test_length = total_length - train_length\n",
        "\n",
        "print(f\"Dataset split:\")\n",
        "print(f\"- Total samples: {total_length}\")\n",
        "print(f\"- Training: {train_length}\")\n",
        "print(f\"- Testing: {test_length}\")\n",
        "\n",
        "train_indices = np.arange(train_length)\n",
        "test_indices = np.arange(train_length, total_length)\n",
        "\n",
        "train_dataset = SParameterDataset(features, targets, window_size, train_indices)\n",
        "test_dataset = SParameterDataset(features, targets, window_size, test_indices)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Data loaders created:\")\n",
        "print(f\"- Train batches: {len(train_loader)}\")\n",
        "print(f\"- Test batches: {len(test_loader)}\")\n",
        "\n",
        "# Test the model\n",
        "model = SParameterPredictionModel(\n",
        "    input_dim=3,  # 3 input S-parameters\n",
        "    d_model=140,\n",
        "    n_heads=4,\n",
        "    n_layers=4,\n",
        "    dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "print(f\"Model created and moved to {device}\")\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training function - same as original but with 3-parameter outputs\n",
        "def train_model(model: nn.Module, train_loader: DataLoader, test_loader: DataLoader, \n",
        "                epochs: int, device: torch.device, lr: float = 1e-4):\n",
        "    print(\"Model device:\", next(model.parameters()).device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    scaler = torch.amp.GradScaler('cuda')\n",
        "    criterion = nn.MSELoss()\n",
        "    \n",
        "    train_losses, test_losses = [], []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for i, (batch_x, batch_y, _) in enumerate(train_loader):\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            if i == 0:\n",
        "                print(f\"Batch shapes - Input: {batch_x.shape}, Target: {batch_y.shape}\")\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                output = model(batch_x)\n",
        "                if torch.isnan(output).any():\n",
        "                    print(f\"NaN in output at epoch {epoch+1}, batch {i}\")\n",
        "                    break\n",
        "                loss = criterion(output, batch_y)\n",
        "            \n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            train_loss += loss.item()\n",
        "        \n",
        "        train_loss /= len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "        \n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_x, batch_y, _ in test_loader:\n",
        "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    output = model(batch_x)\n",
        "                test_loss += criterion(output, batch_y).item()\n",
        "        \n",
        "        test_loss /= len(test_loader)\n",
        "        test_losses.append(test_loss)\n",
        "        \n",
        "        scheduler.step()\n",
        "        \n",
        "        if epoch % 5 == 0 or epoch == epochs - 1:\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f}\")\n",
        "    \n",
        "    return train_losses, test_losses\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "print(f\"Starting training for {epochs} epochs...\")\n",
        "train_losses, test_losses = train_model(model, train_loader, test_loader, epochs, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model and generate predictions\n",
        "def evaluate_model(model, test_loader, dataset):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    time_indices = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y, batch_indices in test_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                output = model(batch_x)\n",
        "            \n",
        "            # Denormalize predictions and targets\n",
        "            output_denorm = dataset.denormalize_predictions(output)\n",
        "            batch_y_denorm = dataset.denormalize_targets(batch_y)\n",
        "            \n",
        "            predictions.append(output_denorm)\n",
        "            actuals.append(batch_y_denorm)\n",
        "            time_indices.append(batch_indices.numpy())\n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    actuals = np.concatenate(actuals, axis=0)\n",
        "    time_indices = np.concatenate(time_indices, axis=0)\n",
        "    \n",
        "    # Sort by time index\n",
        "    sort_idx = np.argsort(time_indices)\n",
        "    time_indices = time_indices[sort_idx]\n",
        "    predictions = predictions[sort_idx]\n",
        "    actuals = actuals[sort_idx]\n",
        "    \n",
        "    return predictions, actuals, time_indices\n",
        "\n",
        "# Evaluate on test set\n",
        "predictions, actuals, time_indices = evaluate_model(model, test_loader, test_dataset)\n",
        "\n",
        "# Calculate RMSE for each S-parameter\n",
        "rmse_s1 = np.sqrt(np.mean((predictions[:, 0] - actuals[:, 0])**2))\n",
        "rmse_s2 = np.sqrt(np.mean((predictions[:, 1] - actuals[:, 1])**2))\n",
        "rmse_s3 = np.sqrt(np.mean((predictions[:, 2] - actuals[:, 2])**2))\n",
        "\n",
        "print(f\"RMSE Results:\")\n",
        "print(f\"S1: {rmse_s1:.6f}\")\n",
        "print(f\"S2: {rmse_s2:.6f}\")\n",
        "print(f\"S3: {rmse_s3:.6f}\")\n",
        "print(f\"Average RMSE: {(rmse_s1 + rmse_s2 + rmse_s3)/3:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot predictions vs actuals for all three S-parameters\n",
        "def plot_s_parameter_predictions(predictions, actuals, time_indices, rmse_s1, rmse_s2, rmse_s3):\n",
        "    plt.figure(figsize=(15, 12))\n",
        "    \n",
        "    # Plot first 1000 points for clarity\n",
        "    n_points = min(1000, len(time_indices))\n",
        "    \n",
        "    # S1 parameter\n",
        "    plt.subplot(3, 2, 1)\n",
        "    plt.plot(time_indices[:n_points], actuals[:n_points, 0], label='Actual S1', color='blue', linewidth=2)\n",
        "    plt.plot(time_indices[:n_points], predictions[:n_points, 0], label='Predicted S1', color='red', linestyle='--', linewidth=2)\n",
        "    plt.title(f'S1 Parameter Time Series (RMSE: {rmse_s1:.6f})')\n",
        "    plt.xlabel('Time Index')\n",
        "    plt.ylabel('S1 Value')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    \n",
        "    plt.subplot(3, 2, 2)\n",
        "    errors_s1 = np.abs(predictions[:n_points, 0] - actuals[:n_points, 0])\n",
        "    plt.plot(time_indices[:n_points], errors_s1, label='|Predicted - Actual| S1', color='purple', linewidth=2)\n",
        "    plt.title(f'S1 Absolute Error')\n",
        "    plt.xlabel('Time Index')\n",
        "    plt.ylabel('Error')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    \n",
        "    # S2 parameter\n",
        "    plt.subplot(3, 2, 3)\n",
        "    plt.plot(time_indices[:n_points], actuals[:n_points, 1], label='Actual S2', color='blue', linewidth=2)\n",
        "    plt.plot(time_indices[:n_points], predictions[:n_points, 1], label='Predicted S2', color='red', linestyle='--', linewidth=2)\n",
        "    plt.title(f'S2 Parameter Time Series (RMSE: {rmse_s2:.6f})')\n",
        "    plt.xlabel('Time Index')\n",
        "    plt.ylabel('S2 Value')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    \n",
        "    plt.subplot(3, 2, 4)\n",
        "    errors_s2 = np.abs(predictions[:n_points, 1] - actuals[:n_points, 1])\n",
        "    plt.plot(time_indices[:n_points], errors_s2, label='|Predicted - Actual| S2', color='purple', linewidth=2)\n",
        "    plt.title(f'S2 Absolute Error')\n",
        "    plt.xlabel('Time Index')\n",
        "    plt.ylabel('Error')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    \n",
        "    # S3 parameter\n",
        "    plt.subplot(3, 2, 5)\n",
        "    plt.plot(time_indices[:n_points], actuals[:n_points, 2], label='Actual S3', color='blue', linewidth=2)\n",
        "    plt.plot(time_indices[:n_points], predictions[:n_points, 2], label='Predicted S3', color='red', linestyle='--', linewidth=2)\n",
        "    plt.title(f'S3 Parameter Time Series (RMSE: {rmse_s3:.6f})')\n",
        "    plt.xlabel('Time Index')\n",
        "    plt.ylabel('S3 Value')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    \n",
        "    plt.subplot(3, 2, 6)\n",
        "    errors_s3 = np.abs(predictions[:n_points, 2] - actuals[:n_points, 2])\n",
        "    plt.plot(time_indices[:n_points], errors_s3, label='|Predicted - Actual| S3', color='purple', linewidth=2)\n",
        "    plt.title(f'S3 Absolute Error')\n",
        "    plt.xlabel('Time Index')\n",
        "    plt.ylabel('Error')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('s_parameter_predictions.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Plot training curves and predictions\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss', color='blue')\n",
        "plt.plot(test_losses, label='Test Loss', color='red')\n",
        "plt.title('Training and Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_losses, label='Train Loss', color='blue')\n",
        "plt.plot(test_losses, label='Test Loss', color='red')\n",
        "plt.title('Training and Test Loss (Log Scale)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('s_parameter_training_loss.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Generate the S-parameter prediction plots\n",
        "plot_s_parameter_predictions(predictions, actuals, time_indices, rmse_s1, rmse_s2, rmse_s3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model size comparison experiments - like original but for S-parameters\n",
        "def experiment_model_sizes(features, targets, window_size: int = 64, batch_size: int = 64, epochs: int = 30):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_configs = [\n",
        "        {'name': 'small', 'd_model': 32, 'n_heads': 4, 'n_layers': 2},\n",
        "        {'name': 'medium', 'd_model': 64, 'n_heads': 8, 'n_layers': 4},\n",
        "        {'name': 'large', 'd_model': 128, 'n_heads': 8, 'n_layers': 6},\n",
        "        {'name': 'extra_large', 'd_model': 256, 'n_heads': 16, 'n_layers': 8}\n",
        "    ]\n",
        "    results = {}\n",
        "    \n",
        "    # Create shared dataset\n",
        "    dataset_full = SParameterDataset(features, targets, window_size)\n",
        "    total_length = len(dataset_full)\n",
        "    train_length = int(0.8 * total_length)\n",
        "    \n",
        "    train_indices = np.arange(train_length)\n",
        "    test_indices = np.arange(train_length, total_length)\n",
        "    \n",
        "    train_dataset = SParameterDataset(features, targets, window_size, train_indices)\n",
        "    test_dataset = SParameterDataset(features, targets, window_size, test_indices)\n",
        "    \n",
        "    for config in model_configs:\n",
        "        model_name = config['name']\n",
        "        print(f\"\\\\nTraining {model_name} model (d_model={config['d_model']}, n_layers={config['n_layers']})...\")\n",
        "        \n",
        "        # Create model\n",
        "        model = SParameterPredictionModel(\n",
        "            input_dim=3,\n",
        "            d_model=config['d_model'],\n",
        "            n_heads=config['n_heads'],\n",
        "            n_layers=config['n_layers'],\n",
        "            dropout=0.1\n",
        "        ).to(device)\n",
        "        \n",
        "        # Create data loaders\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "        \n",
        "        # Train model\n",
        "        train_losses, test_losses = train_model(model, train_loader, test_loader, epochs, device)\n",
        "        \n",
        "        # Evaluate model\n",
        "        predictions, actuals, time_indices = evaluate_model(model, test_loader, test_dataset)\n",
        "        \n",
        "        # Calculate RMSE\n",
        "        rmse_s1 = np.sqrt(np.mean((predictions[:, 0] - actuals[:, 0])**2))\n",
        "        rmse_s2 = np.sqrt(np.mean((predictions[:, 1] - actuals[:, 1])**2))\n",
        "        rmse_s3 = np.sqrt(np.mean((predictions[:, 2] - actuals[:, 2])**2))\n",
        "        avg_rmse = (rmse_s1 + rmse_s2 + rmse_s3) / 3\n",
        "        \n",
        "        results[model_name] = {\n",
        "            'train_losses': train_losses,\n",
        "            'test_losses': test_losses,\n",
        "            'rmse_s1': rmse_s1,\n",
        "            'rmse_s2': rmse_s2,\n",
        "            'rmse_s3': rmse_s3,\n",
        "            'avg_rmse': avg_rmse,\n",
        "            'model': model\n",
        "        }\n",
        "        \n",
        "        print(f\"{model_name} RMSE - S1: {rmse_s1:.6f}, S2: {rmse_s2:.6f}, S3: {rmse_s3:.6f}, Avg: {avg_rmse:.6f}\")\n",
        "        \n",
        "        # Save individual model plots\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(train_losses, label='Train Loss')\n",
        "        plt.plot(test_losses, label='Test Loss')\n",
        "        plt.title(f'Loss Curves - {model_name.title()} Model')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('MSE Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(f's_parameter_loss_{model_name}.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Run model size comparison\n",
        "print(\"Starting model size comparison...\")\n",
        "model_results = experiment_model_sizes(features, targets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot comparison of model performance\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# RMSE comparison\n",
        "plt.subplot(1, 3, 1)\n",
        "model_names = list(model_results.keys())\n",
        "avg_rmses = [model_results[name]['avg_rmse'] for name in model_names]\n",
        "plt.bar(model_names, avg_rmses, color=['lightblue', 'lightgreen', 'lightyellow', 'lightcoral'])\n",
        "plt.title('Average RMSE by Model Size')\n",
        "plt.xlabel('Model Size')\n",
        "plt.ylabel('Average RMSE')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Test loss comparison\n",
        "plt.subplot(1, 3, 2)\n",
        "for name in model_names:\n",
        "    plt.plot(model_results[name]['test_losses'], label=name)\n",
        "plt.title('Test Loss Comparison')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Test Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Individual S-parameter RMSE\n",
        "plt.subplot(1, 3, 3)\n",
        "width = 0.25\n",
        "x = np.arange(len(model_names))\n",
        "s1_rmses = [model_results[name]['rmse_s1'] for name in model_names]\n",
        "s2_rmses = [model_results[name]['rmse_s2'] for name in model_names]\n",
        "s3_rmses = [model_results[name]['rmse_s3'] for name in model_names]\n",
        "\n",
        "plt.bar(x - width, s1_rmses, width, label='S1', color='red', alpha=0.7)\n",
        "plt.bar(x, s2_rmses, width, label='S2', color='green', alpha=0.7)\n",
        "plt.bar(x + width, s3_rmses, width, label='S3', color='blue', alpha=0.7)\n",
        "\n",
        "plt.title('RMSE by S-Parameter and Model')\n",
        "plt.xlabel('Model Size')\n",
        "plt.ylabel('RMSE')\n",
        "plt.xticks(x, model_names, rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('s_parameter_model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Print summary\n",
        "print(\"\\\\nModel Performance Summary:\")\n",
        "print(\"=\" * 80)\n",
        "for name in model_names:\n",
        "    result = model_results[name]\n",
        "    print(f\"{name.upper()}:\")\n",
        "    print(f\"  S1 RMSE: {result['rmse_s1']:.6f}\")\n",
        "    print(f\"  S2 RMSE: {result['rmse_s2']:.6f}\")\n",
        "    print(f\"  S3 RMSE: {result['rmse_s3']:.6f}\")\n",
        "    print(f\"  Avg RMSE: {result['avg_rmse']:.6f}\")\n",
        "    print(f\"  Final Test Loss: {result['test_losses'][-1]:.6f}\")\n",
        "    print()\n",
        "\n",
        "# Find best model\n",
        "best_model_name = min(model_names, key=lambda x: model_results[x]['avg_rmse'])\n",
        "print(f\"Best performing model: {best_model_name.upper()}\")\n",
        "print(f\"Best average RMSE: {model_results[best_model_name]['avg_rmse']:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the best model and results\n",
        "torch.save({\n",
        "    'model_state_dict': model_results[best_model_name]['model'].state_dict(),\n",
        "    'model_config': {\n",
        "        'input_dim': 3,\n",
        "        'd_model': 140,  # This will be updated based on best model\n",
        "        'n_heads': 4,\n",
        "        'n_layers': 4,\n",
        "        'dropout': 0.1\n",
        "    },\n",
        "    'results': model_results,\n",
        "    'normalization_params': {\n",
        "        'features_mean': dataset_full.features_mean,\n",
        "        'features_std': dataset_full.features_std,\n",
        "        'targets_mean': dataset_full.targets_mean,\n",
        "        'targets_std': dataset_full.targets_std\n",
        "    }\n",
        "}, 's_parameter_model.pth')\n",
        "\n",
        "print(f\"Model and results saved to 's_parameter_model.pth'\")\n",
        "print(f\"Training completed successfully!\")\n",
        "print(f\"\\\\nSummary:\")\n",
        "print(f\"- Dataset: {len(features)} samples with 3 input and 3 reference S-parameters\")\n",
        "print(f\"- Best model: {best_model_name}\")\n",
        "print(f\"- Best average RMSE: {model_results[best_model_name]['avg_rmse']:.6f}\")\n",
        "print(f\"- Training completed on {device}\")\n",
        "print(f\"\\\\nThis system trains directly on naive S-parameters without angle conversion!\")\n",
        "print(f\"- Input features: s1_txp, s2_txp, s3_txp\")\n",
        "print(f\"- Target references: s1_pax, s2_pax, s3_pax\")\n",
        "print(f\"- Window size: {window_size}\")\n",
        "print(f\"- Architecture: Transformer with FlashAttention\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
