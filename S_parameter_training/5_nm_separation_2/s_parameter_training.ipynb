{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu128\n",
      "CUDA available: True\n",
      "CUDA version: 12.8\n",
      "GPU count: 1\n",
      "GPU name: NVIDIA RTX A2000\n",
      "Current device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Verify GPU and import libraries\n",
    "import os\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import GradScaler, autocast\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "# Verify GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU count:\", torch.cuda.device_count())\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Current device:\", device)\n",
    "else:\n",
    "    print(\"No GPU detected, using CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading S-parameter data from: ../../Data/basic_datasets/07_19_2025100k_samples_txp_1551.5_pax_1556.5_polcon_and_fiber_2_1Hz.mat\n",
      "Data shapes:\n",
      "s1_pax: (100000,), s2_pax: (100000,), s3_pax: (100000,)\n",
      "s1_txp: (100000,), s2_txp: (100000,), s3_txp: (100000,)\n",
      "\n",
      "Combined data shapes:\n",
      "Features (inputs): (100000, 3)\n",
      "Targets (references): (100000, 3)\n",
      "\n",
      "S-parameter ranges:\n",
      "Input S-parameters - min: -0.999972, max: 0.999999\n",
      "Reference S-parameters - min: -0.999986, max: 0.999996\n"
     ]
    }
   ],
   "source": [
    "# Load and examine the S-parameter data\n",
    "data_path = \"../../Data/basic_datasets/07_19_2025100k_samples_txp_1551.5_pax_1556.5_polcon_and_fiber_2_1Hz.mat\"\n",
    "print(\"Loading S-parameter data from:\", data_path)\n",
    "\n",
    "# Load the .mat file\n",
    "mat_data = scipy.io.loadmat(data_path)\n",
    "\n",
    "# Extract S-parameter data\n",
    "s1_pax = mat_data['s1_pax'].flatten()  # Reference S-parameters\n",
    "s2_pax = mat_data['s2_pax'].flatten()\n",
    "s3_pax = mat_data['s3_pax'].flatten()\n",
    "\n",
    "s1_txp = mat_data['s1_txp'].flatten()  # Input S-parameters\n",
    "s2_txp = mat_data['s2_txp'].flatten()\n",
    "s3_txp = mat_data['s3_txp'].flatten()\n",
    "\n",
    "print(f\"Data shapes:\")\n",
    "print(f\"s1_pax: {s1_pax.shape}, s2_pax: {s2_pax.shape}, s3_pax: {s3_pax.shape}\")\n",
    "print(f\"s1_txp: {s1_txp.shape}, s2_txp: {s2_txp.shape}, s3_txp: {s3_txp.shape}\")\n",
    "\n",
    "# Stack features (inputs) and targets (references)\n",
    "features = np.column_stack([s1_txp, s2_txp, s3_txp])  # 3 input S-parameters\n",
    "targets = np.column_stack([s1_pax, s2_pax, s3_pax])   # 3 reference S-parameters\n",
    "\n",
    "print(f\"\\nCombined data shapes:\")\n",
    "print(f\"Features (inputs): {features.shape}\")\n",
    "print(f\"Targets (references): {targets.shape}\")\n",
    "\n",
    "# Display some statistics\n",
    "print(f\"\\nS-parameter ranges:\")\n",
    "print(f\"Input S-parameters - min: {features.min():.6f}, max: {features.max():.6f}\")\n",
    "print(f\"Reference S-parameters - min: {targets.min():.6f}, max: {targets.max():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class - modified from original to handle 3 S-parameters instead of 2 angles\n",
    "class SParameterDataset(Dataset):\n",
    "    def __init__(self, features: np.ndarray, targets: np.ndarray, window_size: int, indices: np.ndarray = None):\n",
    "        \"\"\"\n",
    "        Dataset for S-parameter prediction\n",
    "        \n",
    "        Args:\n",
    "            features: Input S-parameters (N, 3)\n",
    "            targets: Target S-parameters (N, 3) \n",
    "            window_size: Size of the sliding window\n",
    "            indices: Optional indices for train/test split\n",
    "        \"\"\"\n",
    "        # Check for NaN or infinite values\n",
    "        if np.isnan(features).any() or np.isnan(targets).any():\n",
    "            print(\"Warning: NaN values found in data!\")\n",
    "            valid_mask = ~(np.isnan(features).any(axis=1) | np.isnan(targets).any(axis=1))\n",
    "            features = features[valid_mask]\n",
    "            targets = targets[valid_mask]\n",
    "            \n",
    "        if np.isinf(features).any() or np.isinf(targets).any():\n",
    "            print(\"Warning: Infinite values found in data!\")\n",
    "            valid_mask = ~(np.isinf(features).any(axis=1) | np.isinf(targets).any(axis=1))\n",
    "            features = features[valid_mask]\n",
    "            targets = targets[valid_mask]\n",
    "        \n",
    "        # Normalize the data\n",
    "        self.features_mean = np.mean(features, axis=0)\n",
    "        self.features_std = np.std(features, axis=0) + 1e-8\n",
    "        self.targets_mean = np.mean(targets, axis=0)\n",
    "        self.targets_std = np.std(targets, axis=0) + 1e-8\n",
    "        \n",
    "        self.features = (features - self.features_mean) / self.features_std\n",
    "        self.targets = (targets - self.targets_mean) / self.targets_std\n",
    "        \n",
    "        print(f\"Normalized features range: {self.features.min():.3f} to {self.features.max():.3f}\")\n",
    "        print(f\"Normalized targets range: {self.targets.min():.3f} to {self.targets.max():.3f}\")\n",
    "        \n",
    "        self.window_size = window_size\n",
    "        self.indices = indices if indices is not None else np.arange(len(self.features) - window_size + 1)\n",
    "        self.length = len(self.indices)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        data_idx = self.indices[idx]\n",
    "        window = self.features[data_idx:data_idx + self.window_size]\n",
    "        target = self.targets[data_idx + self.window_size - 1]\n",
    "        time_index = data_idx + self.window_size - 1\n",
    "        return torch.FloatTensor(window), torch.FloatTensor(target), time_index\n",
    "    \n",
    "    def denormalize_predictions(self, predictions):\n",
    "        \"\"\"Convert normalized predictions back to original scale\"\"\"\n",
    "        if isinstance(predictions, torch.Tensor):\n",
    "            predictions = predictions.cpu().numpy()\n",
    "        return predictions * self.targets_std + self.targets_mean\n",
    "    \n",
    "    def denormalize_targets(self, targets):\n",
    "        \"\"\"Convert normalized targets back to original scale\"\"\"\n",
    "        if isinstance(targets, torch.Tensor):\n",
    "            targets = targets.cpu().numpy()\n",
    "        return targets * self.targets_std + self.targets_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition - modified from original to handle 3 inputs/outputs instead of 2\n",
    "class FlashAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, n_heads: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.qkv = nn.Linear(d_model, 3 * d_model)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, T, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, T, 3, self.n_heads, self.d_k).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        \n",
    "        scale = 1.0 / torch.sqrt(torch.tensor(self.d_k, dtype=torch.float32))\n",
    "        attn = torch.matmul(q, k.transpose(-2, -1)) * scale\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "        \n",
    "        out = torch.matmul(attn, v)\n",
    "        out = out.transpose(1, 2).reshape(B, T, C)\n",
    "        out = self.out(out)\n",
    "        return out\n",
    "\n",
    "class SParameterPredictionModel(nn.Module):\n",
    "    def __init__(self, input_dim: int, d_model: int, n_heads: int, n_layers: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoding = nn.Parameter(torch.randn(1, 128, d_model) * 0.1)\n",
    "        self.attn_layers = nn.ModuleList([\n",
    "            FlashAttention(d_model, n_heads, dropout) for _ in range(n_layers)\n",
    "        ])\n",
    "        self.norm_layers = nn.ModuleList([\n",
    "            nn.LayerNorm(d_model) for _ in range(n_layers)\n",
    "        ])\n",
    "        self.output = nn.Linear(d_model, 3)  # Output 3 S-parameters instead of 2\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.input_proj(x)\n",
    "        x = x + self.pos_encoding[:, :x.size(1), :]\n",
    "        \n",
    "        for attn, norm in zip(self.attn_layers, self.norm_layers):\n",
    "            residual = x\n",
    "            x = attn(x)\n",
    "            x = norm(x + residual)\n",
    "        \n",
    "        x = x[:, -1, :]\n",
    "        return self.output(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized features range: -1.906 to 1.702\n",
      "Normalized targets range: -2.095 to 1.842\n",
      "Dataset split:\n",
      "- Total samples: 99937\n",
      "- Training: 79949\n",
      "- Testing: 19988\n",
      "Normalized features range: -1.906 to 1.702\n",
      "Normalized targets range: -2.095 to 1.842\n",
      "Normalized features range: -1.906 to 1.702\n",
      "Normalized targets range: -2.095 to 1.842\n",
      "Data loaders created:\n",
      "- Train batches: 1250\n",
      "- Test batches: 313\n",
      "Model created and moved to cuda\n",
      "Model parameters: 335863\n"
     ]
    }
   ],
   "source": [
    "# Create dataset and data loaders\n",
    "window_size = 64\n",
    "batch_size = 64\n",
    "\n",
    "dataset_full = SParameterDataset(features, targets, window_size)\n",
    "total_length = len(dataset_full)\n",
    "train_length = int(0.8 * total_length)\n",
    "test_length = total_length - train_length\n",
    "\n",
    "print(f\"Dataset split:\")\n",
    "print(f\"- Total samples: {total_length}\")\n",
    "print(f\"- Training: {train_length}\")\n",
    "print(f\"- Testing: {test_length}\")\n",
    "\n",
    "train_indices = np.arange(train_length)\n",
    "test_indices = np.arange(train_length, total_length)\n",
    "\n",
    "train_dataset = SParameterDataset(features, targets, window_size, train_indices)\n",
    "test_dataset = SParameterDataset(features, targets, window_size, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Data loaders created:\")\n",
    "print(f\"- Train batches: {len(train_loader)}\")\n",
    "print(f\"- Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Test the model\n",
    "model = SParameterPredictionModel(\n",
    "    input_dim=3,  # 3 input S-parameters\n",
    "    d_model=140,\n",
    "    n_heads=4,\n",
    "    n_layers=4,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model created and moved to {device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 50 epochs...\n",
      "Model device: cuda:0\n",
      "Batch shapes - Input: torch.Size([64, 64, 3]), Target: torch.Size([64, 3])\n",
      "Epoch 1/50, Train Loss: 0.037361, Test Loss: 0.012979\n",
      "Batch shapes - Input: torch.Size([64, 64, 3]), Target: torch.Size([64, 3])\n",
      "Epoch 2/50, Train Loss: 0.008305, Test Loss: 0.014627\n",
      "Batch shapes - Input: torch.Size([64, 64, 3]), Target: torch.Size([64, 3])\n"
     ]
    }
   ],
   "source": [
    "# Training function - same as original but with 3-parameter outputs\n",
    "def train_model(model: nn.Module, train_loader: DataLoader, test_loader: DataLoader, \n",
    "                epochs: int, device: torch.device, lr: float = 1e-4):\n",
    "    print(\"Model device:\", next(model.parameters()).device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    train_losses, test_losses = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for i, (batch_x, batch_y, _) in enumerate(train_loader):\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            if i == 0:\n",
    "                print(f\"Batch shapes - Input: {batch_x.shape}, Target: {batch_y.shape}\")\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                output = model(batch_x)\n",
    "                if torch.isnan(output).any():\n",
    "                    print(f\"NaN in output at epoch {epoch+1}, batch {i}\")\n",
    "                    break\n",
    "                loss = criterion(output, batch_y)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y, _ in test_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    output = model(batch_x)\n",
    "                test_loss += criterion(output, batch_y).item()\n",
    "        \n",
    "        test_loss /= len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f}\")\n",
    "    \n",
    "    return train_losses, test_losses\n",
    "\n",
    "# Train the model\n",
    "epochs = 50\n",
    "print(f\"Starting training for {epochs} epochs...\")\n",
    "train_losses, test_losses = train_model(model, train_loader, test_loader, epochs, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and generate predictions\n",
    "def evaluate_model(model, test_loader, dataset):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    time_indices = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, batch_indices in test_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                output = model(batch_x)\n",
    "            \n",
    "            # Denormalize predictions and targets\n",
    "            output_denorm = dataset.denormalize_predictions(output)\n",
    "            batch_y_denorm = dataset.denormalize_targets(batch_y)\n",
    "            \n",
    "            predictions.append(output_denorm)\n",
    "            actuals.append(batch_y_denorm)\n",
    "            time_indices.append(batch_indices.numpy())\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    actuals = np.concatenate(actuals, axis=0)\n",
    "    time_indices = np.concatenate(time_indices, axis=0)\n",
    "    \n",
    "    # Sort by time index\n",
    "    sort_idx = np.argsort(time_indices)\n",
    "    time_indices = time_indices[sort_idx]\n",
    "    predictions = predictions[sort_idx]\n",
    "    actuals = actuals[sort_idx]\n",
    "    \n",
    "    return predictions, actuals, time_indices\n",
    "\n",
    "# Evaluate on test set\n",
    "predictions, actuals, time_indices = evaluate_model(model, test_loader, test_dataset)\n",
    "\n",
    "# Calculate RMSE for each S-parameter\n",
    "rmse_s1 = np.sqrt(np.mean((predictions[:, 0] - actuals[:, 0])**2))\n",
    "rmse_s2 = np.sqrt(np.mean((predictions[:, 1] - actuals[:, 1])**2))\n",
    "rmse_s3 = np.sqrt(np.mean((predictions[:, 2] - actuals[:, 2])**2))\n",
    "\n",
    "print(f\"RMSE Results:\")\n",
    "print(f\"S1: {rmse_s1:.6f}\")\n",
    "print(f\"S2: {rmse_s2:.6f}\")\n",
    "print(f\"S3: {rmse_s3:.6f}\")\n",
    "print(f\"Average RMSE: {(rmse_s1 + rmse_s2 + rmse_s3)/3:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot predictions vs actuals for all three S-parameters\n",
    "def plot_s_parameter_predictions(predictions, actuals, time_indices, rmse_s1, rmse_s2, rmse_s3, data_dict):\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Plot first 1000 points for clarity\n",
    "    n_points = min(1000, len(time_indices))\n",
    "    data_dict['time_indices'] = time_indices\n",
    "    # S1 parameter\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.plot(time_indices[:n_points], actuals[:n_points, 0], label='Actual S1', color='blue', linewidth=2)\n",
    "    plt.plot(time_indices[:n_points], predictions[:n_points, 0], label='Predicted S1', color='red', linestyle='--', linewidth=2)\n",
    "    plt.title(f'S1 Parameter Time Series (RMSE: {rmse_s1:.6f})')\n",
    "    plt.xlabel('Time Index')\n",
    "    plt.ylabel('S1 Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    data_dict['s1_actual'] = actuals[:,0]\n",
    "    data_dict['s1_prediction'] = predictions[:, 0]\n",
    "    \n",
    "    plt.subplot(3, 2, 2)\n",
    "    errors_s1 = np.abs(predictions[:,0] - actuals[:,0])\n",
    "    plt.plot(time_indices[:n_points], errors_s1[:n_points], label='|Predicted - Actual| S1', color='purple', linewidth=2)\n",
    "    plt.title(f'S1 Absolute Error')\n",
    "    plt.xlabel('Time Index')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    data_dict['errors_s1'] = errors_s1\n",
    "    # S2 parameter\n",
    "    plt.subplot(3, 2, 3)\n",
    "    plt.plot(time_indices[:n_points], actuals[:n_points, 1], label='Actual S2', color='blue', linewidth=2)\n",
    "    plt.plot(time_indices[:n_points], predictions[:n_points, 1], label='Predicted S2', color='red', linestyle='--', linewidth=2)\n",
    "    plt.title(f'S2 Parameter Time Series (RMSE: {rmse_s2:.6f})')\n",
    "    plt.xlabel('Time Index')\n",
    "    plt.ylabel('S2 Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    data_dict['s2_actual'] = actuals[:,1]\n",
    "    data_dict['s2_prediction'] = predictions[:, 1]\n",
    "    plt.subplot(3, 2, 4)\n",
    "    errors_s2 = np.abs(predictions[:, 1] - actuals[:, 1])\n",
    "    plt.plot(time_indices[:n_points], errors_s2[:n_points], label='|Predicted - Actual| S2', color='purple', linewidth=2)\n",
    "    plt.title(f'S2 Absolute Error')\n",
    "    plt.xlabel('Time Index')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    data_dict['errors_s2'] = errors_s2\n",
    "    # S3 parameter\n",
    "    plt.subplot(3, 2, 5)\n",
    "    plt.plot(time_indices[:n_points], actuals[:n_points, 2], label='Actual S3', color='blue', linewidth=2)\n",
    "    plt.plot(time_indices[:n_points], predictions[:n_points, 2], label='Predicted S3', color='red', linestyle='--', linewidth=2)\n",
    "    plt.title(f'S3 Parameter Time Series (RMSE: {rmse_s3:.6f})')\n",
    "    plt.xlabel('Time Index')\n",
    "    plt.ylabel('S3 Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    data_dict['s3_actual'] = actuals[:,2]\n",
    "    data_dict['s3_prediction'] = predictions[:, 2]\n",
    "    plt.subplot(3, 2, 6)\n",
    "    errors_s3 = np.abs(predictions[:, 2] - actuals[:, 2])\n",
    "    plt.plot(time_indices[:n_points], errors_s3[:n_points], label='|Predicted - Actual| S3', color='purple', linewidth=2)\n",
    "    plt.title(f'S3 Absolute Error')\n",
    "    plt.xlabel('Time Index')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    data_dict['errors_s3'] = errors_s3\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('s_parameter_predictions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(data_dict.keys())\n",
    "# Plot training curves and predictions\n",
    "data_dict = {}\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss', color='blue')\n",
    "plt.plot(test_losses, label='Test Loss', color='red')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "data_dict['train_losses'] = train_losses\n",
    "data_dict['test_losses'] = test_losses\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses, label='Train Loss', color='blue')\n",
    "plt.plot(test_losses, label='Test Loss', color='red')\n",
    "plt.title('Training and Test Loss (Log Scale)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('s_parameter_training_loss.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Generate the S-parameter prediction plots\n",
    "plot_s_parameter_predictions(predictions, actuals, time_indices, rmse_s1, rmse_s2, rmse_s3, data_dict)\n",
    "\n",
    "scipy.io.savemat('training_and_prediction_data.mat', data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data from: ../../Data/basic_datasets/07_19_2025100k_samples_txp_1551.5_pax_1556.5_polcon_and_fiber_1Hz.mat\n",
      "Starting window size comparison...\n",
      "\n",
      "Experimenting with window size: 8\n",
      "Normalized features range: -1.848 to 1.810\n",
      "Normalized targets range: -1.822 to 1.797\n",
      "Normalized features range: -1.848 to 1.810\n",
      "Normalized targets range: -1.822 to 1.797\n",
      "Normalized features range: -1.848 to 1.810\n",
      "Normalized targets range: -1.822 to 1.797\n",
      "Model device: cuda:0\n",
      "Batch shapes - Input: torch.Size([64, 8, 3]), Target: torch.Size([64, 3])\n",
      "Epoch 1/50, Train Loss: 0.023991, Test Loss: 0.017408\n",
      "Batch shapes - Input: torch.Size([64, 8, 3]), Target: torch.Size([64, 3])\n",
      "Epoch 2/50, Train Loss: 0.007913, Test Loss: 0.017134\n",
      "Batch shapes - Input: torch.Size([64, 8, 3]), Target: torch.Size([64, 3])\n",
      "Epoch 3/50, Train Loss: 0.007090, Test Loss: 0.018833\n",
      "Batch shapes - Input: torch.Size([64, 8, 3]), Target: torch.Size([64, 3])\n",
      "Epoch 4/50, Train Loss: 0.006733, Test Loss: 0.013049\n",
      "Batch shapes - Input: torch.Size([64, 8, 3]), Target: torch.Size([64, 3])\n",
      "Epoch 5/50, Train Loss: 0.006516, Test Loss: 0.016045\n",
      "Batch shapes - Input: torch.Size([64, 8, 3]), Target: torch.Size([64, 3])\n",
      "Epoch 6/50, Train Loss: 0.006419, Test Loss: 0.013018\n",
      "Batch shapes - Input: torch.Size([64, 8, 3]), Target: torch.Size([64, 3])\n",
      "Epoch 7/50, Train Loss: 0.006224, Test Loss: 0.022989\n",
      "Batch shapes - Input: torch.Size([64, 8, 3]), Target: torch.Size([64, 3])\n",
      "Epoch 8/50, Train Loss: 0.006169, Test Loss: 0.014349\n",
      "Batch shapes - Input: torch.Size([64, 8, 3]), Target: torch.Size([64, 3])\n",
      "Epoch 9/50, Train Loss: 0.006115, Test Loss: 0.015419\n",
      "Batch shapes - Input: torch.Size([64, 8, 3]), Target: torch.Size([64, 3])\n",
      "Epoch 10/50, Train Loss: 0.006080, Test Loss: 0.014816\n",
      "Batch shapes - Input: torch.Size([64, 8, 3]), Target: torch.Size([64, 3])\n",
      "Epoch 11/50, Train Loss: 0.005985, Test Loss: 0.014978\n",
      "Batch shapes - Input: torch.Size([64, 8, 3]), Target: torch.Size([64, 3])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 184\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting window size comparison...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    183\u001b[0m window_sizes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m]\n\u001b[1;32m--> 184\u001b[0m window_results \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment_window_sizes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting model size comparison...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    187\u001b[0m model_results \u001b[38;5;241m=\u001b[39m experiment_model_sizes(features, targets)\n",
      "Cell \u001b[1;32mIn [16], line 115\u001b[0m, in \u001b[0;36mexperiment_window_sizes\u001b[1;34m(features, targets, data_path, window_sizes, batch_size, epochs)\u001b[0m\n\u001b[0;32m    112\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m train_losses, test_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[0;32m    118\u001b[0m predictions, actuals, time_indices \u001b[38;5;241m=\u001b[39m evaluate_model(model, test_loader, test_dataset)\n",
      "Cell \u001b[1;32mIn [7], line 28\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, test_loader, epochs, device, lr)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, batch_y)\n\u001b[1;32m---> 28\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m scaler\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m     30\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model size comparison experiments - like original but for S-parameters\n",
    "def experiment_model_sizes(features, targets, window_size: int = 64, batch_size: int = 64, epochs: int = 50):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_configs = [\n",
    "        {'name': 'small', 'd_model': 16, 'n_heads': 4, 'n_layers': 1},\n",
    "        {'name': 'medium', 'd_model': 32, 'n_heads': 4, 'n_layers': 2},\n",
    "        {'name': 'large', 'd_model': 64, 'n_heads': 8, 'n_layers': 3},\n",
    "        # Extra Large: Increase d_model to ~140 to get ~5x parameters\n",
    "        {'name': 'extra_large', 'd_model': 140, 'n_heads': 10, 'n_layers': 4}\n",
    "    ]\n",
    "    results = {}\n",
    "    data_dict = {}\n",
    "    # Create shared dataset\n",
    "    dataset_full = SParameterDataset(features, targets, window_size)\n",
    "    total_length = len(dataset_full)\n",
    "    train_length = int(0.8 * total_length)\n",
    "    \n",
    "    train_indices = np.arange(train_length)\n",
    "    test_indices = np.arange(train_length, total_length)\n",
    "    \n",
    "    train_dataset = SParameterDataset(features, targets, window_size, train_indices)\n",
    "    test_dataset = SParameterDataset(features, targets, window_size, test_indices)\n",
    "    \n",
    "    for config in model_configs:\n",
    "        model_name = config['name']\n",
    "        print(f\"\\\\nTraining {model_name} model (d_model={config['d_model']}, n_layers={config['n_layers']})...\")\n",
    "        \n",
    "        # Create model\n",
    "        model = SParameterPredictionModel(\n",
    "            input_dim=3,\n",
    "            d_model=config['d_model'],\n",
    "            n_heads=config['n_heads'],\n",
    "            n_layers=config['n_layers'],\n",
    "            dropout=0.1\n",
    "        ).to(device)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Train model\n",
    "        train_losses, test_losses = train_model(model, train_loader, test_loader, epochs, device)\n",
    "        \n",
    "        # Evaluate model\n",
    "        predictions, actuals, time_indices = evaluate_model(model, test_loader, test_dataset)\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        rmse_s1 = np.sqrt(np.mean((predictions[:, 0] - actuals[:, 0])**2))\n",
    "        rmse_s2 = np.sqrt(np.mean((predictions[:, 1] - actuals[:, 1])**2))\n",
    "        rmse_s3 = np.sqrt(np.mean((predictions[:, 2] - actuals[:, 2])**2))\n",
    "        avg_rmse = (rmse_s1 + rmse_s2 + rmse_s3) / 3\n",
    "        \n",
    "        results[model_name] = {\n",
    "            'train_losses': train_losses,\n",
    "            'test_losses': test_losses,\n",
    "            'rmse_s1': rmse_s1,\n",
    "            'rmse_s2': rmse_s2,\n",
    "            'rmse_s3': rmse_s3,\n",
    "            'avg_rmse': avg_rmse,\n",
    "            'model': model\n",
    "        }\n",
    "        \n",
    "        print(f\"{model_name} RMSE - S1: {rmse_s1:.6f}, S2: {rmse_s2:.6f}, S3: {rmse_s3:.6f}, Avg: {avg_rmse:.6f}\")\n",
    "        \n",
    "        # Save individual model plots\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(train_losses, label='Train Loss')\n",
    "        plt.plot(test_losses, label='Test Loss')\n",
    "        plt.title(f'Loss Curves - {model_name.title()} Model')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('MSE Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f's_parameter_loss_{model_name}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        data_dict[f'{model_name}_test_loss'] = test_losses\n",
    "        data_dict[f'{model_name}_train_loss'] = train_losses\n",
    "\n",
    "    scipy.io.savemat('model_size_losses.mat', data_dict)\n",
    "    return results\n",
    "    \n",
    "def experiment_window_sizes(features, targets, data_path: str, window_sizes: list, batch_size: int = 64, epochs: int = 50):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    results = {}\n",
    "    data_dict = {}\n",
    "    for window_size in window_sizes:\n",
    "        print(f\"\\nExperimenting with window size: {window_size}\")\n",
    "        model_name = f'window_model_{window_size}'\n",
    "        dataset_full = SParameterDataset(features, targets, window_size)\n",
    "        total_length = len(dataset_full)\n",
    "        train_length = int(0.8 * total_length)\n",
    "        test_length = total_length - train_length\n",
    "        \n",
    "        train_indices = np.arange(train_length)\n",
    "        test_indices = np.arange(train_length, total_length)\n",
    "        \n",
    "        train_dataset = SParameterDataset(features, targets, window_size, train_indices)\n",
    "        test_dataset = SParameterDataset(features, targets, window_size, test_indices)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        model = SParameterPredictionModel(\n",
    "            input_dim=3,\n",
    "            d_model=140,\n",
    "            n_heads=4,\n",
    "            n_layers=4,\n",
    "            dropout=0.1\n",
    "        ).to(device)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Train model\n",
    "        train_losses, test_losses = train_model(model, train_loader, test_loader, epochs, device)\n",
    "        \n",
    "        # Evaluate model\n",
    "        predictions, actuals, time_indices = evaluate_model(model, test_loader, test_dataset)\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        rmse_s1 = np.sqrt(np.mean((predictions[:, 0] - actuals[:, 0])**2))\n",
    "        rmse_s2 = np.sqrt(np.mean((predictions[:, 1] - actuals[:, 1])**2))\n",
    "        rmse_s3 = np.sqrt(np.mean((predictions[:, 2] - actuals[:, 2])**2))\n",
    "        avg_rmse = (rmse_s1 + rmse_s2 + rmse_s3) / 3\n",
    "        \n",
    "        \n",
    "        predictions = np.concatenate(predictions, axis=0)\n",
    "        actuals = np.concatenate(actuals, axis=0)\n",
    "        time_indices = np.concatenate(time_indices, axis=0)\n",
    "        \n",
    "        sort_idx = np.argsort(time_indices)\n",
    "        time_indices = time_indices[sort_idx]\n",
    "        predictions = predictions[sort_idx]\n",
    "        actuals = actuals[sort_idx]\n",
    "        \n",
    "        print(f\"{model_name} RMSE - S1: {rmse_s1:.6f}, S2: {rmse_s2:.6f}, S3: {rmse_s3:.6f}, Avg: {avg_rmse:.6f}\")\n",
    "        \n",
    "        results[window_size] = {\n",
    "            'train_losses': train_losses,\n",
    "            'test_losses': test_losses,\n",
    "            'model': model,\n",
    "            'predictions': predictions,\n",
    "            'actuals': actuals,\n",
    "            'time_indices': time_indices,\n",
    "            'rmse_phi': rmse_phi,\n",
    "            'rmse_theta': rmse_theta\n",
    "        }\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(train_losses, label='Train Loss')\n",
    "        plt.plot(test_losses, label='Test Loss')\n",
    "        plt.title(f'Loss Curves (Window Size: {window_size})')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('MSE Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f'loss_window_{window_size}.png')\n",
    "        plt.close()\n",
    "        data_dict = {}\n",
    "        data_dict['train_losses'] = train_losses\n",
    "        data_dict['test_losses'] = test_losses\n",
    "        data_dict = {**data_dict, **results[window_size]}\n",
    "        savemat(f'loss_window_{window_size}.mat', data_dict)\n",
    "        \n",
    "\n",
    "    data_dict = {}\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for window_size, result in results.items():\n",
    "        plt.plot(result['test_losses'], label=f'Window {window_size}')\n",
    "        data_dict[f'window_{window_size}_loss'] = result['test_losses']\n",
    "    plt.title('Test Loss Comparison Across Window Sizes')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('window_size_comparison.png')\n",
    "    plt.close()\n",
    "    savemat('window_size_comparison.mat', data_dict)\n",
    "    return results\n",
    "# Run model size comparison\n",
    "print(f'Loading Data from: {data_path}')\n",
    "print(\"Starting window size comparison...\")\n",
    "window_sizes = [8, 16, 32, 64, 128]\n",
    "window_results = experiment_window_sizes(features, targets, data_path, window_sizes)\n",
    "\n",
    "print('Starting model size comparison...')\n",
    "model_results = experiment_model_sizes(features, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison of model performance\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# RMSE comparison\n",
    "plt.subplot(1, 3, 1)\n",
    "model_names = list(model_results.keys())\n",
    "avg_rmses = [model_results[name]['avg_rmse'] for name in model_names]\n",
    "plt.bar(model_names, avg_rmses, color=['lightblue', 'lightgreen', 'lightyellow', 'lightcoral'])\n",
    "plt.title('Average RMSE by Model Size')\n",
    "plt.xlabel('Model Size')\n",
    "plt.ylabel('Average RMSE')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Test loss comparison\n",
    "plt.subplot(1, 3, 2)\n",
    "for name in model_names:\n",
    "    plt.plot(model_results[name]['test_losses'], label=name)\n",
    "plt.title('Test Loss Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Individual S-parameter RMSE\n",
    "plt.subplot(1, 3, 3)\n",
    "width = 0.25\n",
    "x = np.arange(len(model_names))\n",
    "s1_rmses = [model_results[name]['rmse_s1'] for name in model_names]\n",
    "s2_rmses = [model_results[name]['rmse_s2'] for name in model_names]\n",
    "s3_rmses = [model_results[name]['rmse_s3'] for name in model_names]\n",
    "\n",
    "plt.bar(x - width, s1_rmses, width, label='S1', color='red', alpha=0.7)\n",
    "plt.bar(x, s2_rmses, width, label='S2', color='green', alpha=0.7)\n",
    "plt.bar(x + width, s3_rmses, width, label='S3', color='blue', alpha=0.7)\n",
    "\n",
    "plt.title('RMSE by S-Parameter and Model')\n",
    "plt.xlabel('Model Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(x, model_names, rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('s_parameter_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\\\nModel Performance Summary:\")\n",
    "print(\"=\" * 80)\n",
    "for name in model_names:\n",
    "    result = model_results[name]\n",
    "    print(f\"{name.upper()}:\")\n",
    "    print(f\"  S1 RMSE: {result['rmse_s1']:.6f}\")\n",
    "    print(f\"  S2 RMSE: {result['rmse_s2']:.6f}\")\n",
    "    print(f\"  S3 RMSE: {result['rmse_s3']:.6f}\")\n",
    "    print(f\"  Avg RMSE: {result['avg_rmse']:.6f}\")\n",
    "    print(f\"  Final Test Loss: {result['test_losses'][-1]:.6f}\")\n",
    "    print()\n",
    "\n",
    "# Find best model\n",
    "best_model_name = min(model_names, key=lambda x: model_results[x]['avg_rmse'])\n",
    "print(f\"Best performing model: {best_model_name.upper()}\")\n",
    "print(f\"Best average RMSE: {model_results[best_model_name]['avg_rmse']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model and results\n",
    "torch.save({\n",
    "    'model_state_dict': model_results[best_model_name]['model'].state_dict(),\n",
    "    'model_config': {\n",
    "        'input_dim': 3,\n",
    "        'd_model': 140,  # This will be updated based on best model\n",
    "        'n_heads': 4,\n",
    "        'n_layers': 4,\n",
    "        'dropout': 0.1\n",
    "    },\n",
    "    'results': model_results,\n",
    "    'normalization_params': {\n",
    "        'features_mean': dataset_full.features_mean,\n",
    "        'features_std': dataset_full.features_std,\n",
    "        'targets_mean': dataset_full.targets_mean,\n",
    "        'targets_std': dataset_full.targets_std\n",
    "    }\n",
    "}, 's_parameter_model.pth')\n",
    "\n",
    "print(f\"Model and results saved to 's_parameter_model.pth'\")\n",
    "print(f\"Training completed successfully!\")\n",
    "print(f\"\\\\nSummary:\")\n",
    "print(f\"- Dataset: {len(features)} samples with 3 input and 3 reference S-parameters\")\n",
    "print(f\"- Best model: {best_model_name}\")\n",
    "print(f\"- Best average RMSE: {model_results[best_model_name]['avg_rmse']:.6f}\")\n",
    "print(f\"- Training completed on {device}\")\n",
    "print(f\"\\\\nThis system trains directly on naive S-parameters without angle conversion!\")\n",
    "print(f\"- Input features: s1_txp, s2_txp, s3_txp\")\n",
    "print(f\"- Target references: s1_pax, s2_pax, s3_pax\")\n",
    "print(f\"- Window size: {window_size}\")\n",
    "print(f\"- Architecture: Transformer with FlashAttention\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
